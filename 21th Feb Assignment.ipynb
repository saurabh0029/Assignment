{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cab74ddd-b5c3-4437-818c-23600e5e2095",
   "metadata": {},
   "source": [
    "                                                        21th Feb Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cad674-3724-470a-97e7-92231e8b4dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1. Ans \n",
    "\n",
    "# What is Web Scraping?\n",
    "\n",
    "Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is\n",
    "then converted into structured data in a spreadsheet or a database so that it can be used in various applications. There are many different ways to \n",
    "perform web scraping to obtain data from websites. These include using online services, particular API’s or even creating your code for web scraping\n",
    "from scratch. \n",
    "\n",
    "\n",
    "#Why it is used?\n",
    "\n",
    "It is used for :-\n",
    "\n",
    "    Data Collection :- Collect data from multiple websites for market research and competitor analysis.\n",
    "\n",
    "    Content Aggregation :- Gather information about content from multiple sources to populate a news feed.\n",
    "\n",
    "    Search Engine Indexing :- Crawl and index websites so end users can find information online.\n",
    "\n",
    "    Machine Learning :- Build training datasets for machine learning models.\n",
    "\n",
    "    Price Monitoring :- Monitor price changes on e-commerce websites.\n",
    "\n",
    "    Lead Generation :- Collect corporate contact information, including email addresses and phone numbers.\n",
    "    \n",
    "    \n",
    "# Give three areas where Web Scraping is used to get data.\n",
    "\n",
    "\n",
    "1. Price Monitoring\n",
    "2. Applying machine learning techniques\n",
    "3. News Monitoring\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb51905c-1823-44c1-9457-712268af1c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q2. Ans\n",
    "\n",
    "# What are the different methods used for Web Scraping?\n",
    "\n",
    "The different methods used for Web Scraping are:-\n",
    "\n",
    "1.Human copy-and-paste.\n",
    "2.Text pattern matching.\n",
    "3.HTTP programming.\n",
    "4.HTML parsing.\n",
    "5.DOM parsing.\n",
    "6.Vertical aggregation.\n",
    "7.Semantic annotation recognizing.\n",
    "8.Computer vision web-page analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d8ba5d-fc7f-4090-84f1-4ff5edef72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q3. Ans\n",
    "\n",
    "# What is Beautiful Soup?\n",
    "\n",
    "Beautiful Soup is a Python library that makes it easy to scrape information from web pages. It sits atop an HTML or XML parser and provides Pythonic\n",
    "idioms for iterating, searching, and modifying the parse tree.\n",
    "\n",
    "# Why is it used?\n",
    "\n",
    "The Beautiful Soup library helps with isolating titles and links from webpages. It can extract all of the text from ​HTML tags, and alter the \n",
    "HTML in the document with which we are working.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65650dff-4eb0-45fd-b64a-5cbc2c9b58a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q4. Ans\n",
    "\n",
    "# Why is flask used in this Web Scraping project?\n",
    "\n",
    "Flask is used in this Web Scraping project for :-\n",
    "\n",
    "1. creating a web interface to display the results of the scraping.\n",
    "2. To create API and routing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e73578-297b-489f-b5c1-c98ed4f61de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q5. Ans\n",
    "\n",
    "# Write the names of AWS services used in this project. Also , explain the use of each service.\n",
    "\n",
    "CodePipeline and Elastic Beanstalk are used in this project.\n",
    "\n",
    "\n",
    "CodePipeline :- \n",
    "\n",
    "CodePipeline is a fully managed continuous delivery service provided by Amazon Web Services(AWS). It enables us to automate our software release \n",
    "processes for bulding, testing , and deploying our code changes to various environements.\n",
    "\n",
    "Some benefits of using CodePipeline include:\n",
    "    \n",
    "    i. Increased speed and efficiency in delivering software changes.\n",
    "    ii. Consistent and reliable deployments.\n",
    "    iii. Ability to detect and prevent potential issuses earlu in the process.\n",
    "    iv. Increased visibility into the status of each stage and overall pipeline performance.\n",
    "    \n",
    "    \n",
    "    \n",
    "Elastic Beanstalk :-\n",
    "\n",
    "Elastic Beanstalk is a platform within AWS that is used for deploying and scaling web applications. In simple terms this platform as a service (PaaS)\n",
    "takes your application code and deploys it while provisioning the supporting architecture and compute resources required for your code to run.\n",
    "Elastic Beanstalk also fully manages the patching and security updates for those provisioned resources. \n",
    "\n",
    "Some benefits of Elastic Beanstalk include:\n",
    "    \n",
    "    i. Simplified deployment :- Elastic Beanstalk provides a simple and easy to use interface that allows you deploy your code with a few clikes.\n",
    "    \n",
    "    ii. Auto-scaling :- Elastic Beanstalk can automatically scale your appication up or down based on traffic, ensuring that your application \n",
    "                        can handle high traffic loads without manual intervention.\n",
    "        \n",
    "    iii. Monitoring and logging :- Elastic Beanstalk provides built-in monitoring and logging capabilities, allowing you to track the health and \n",
    "                                    performance of your application\n",
    "        \n",
    "    iv.Easy customization :- Elastic Beanstalk allows you to customize the underlying infrastructure resources to meet your specific needs, includeng specific need.\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
